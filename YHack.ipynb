{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import requests \n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from google_images_download import google_images_download   #importing the library\n",
    "from IPython.display import Image\n",
    "import googlemaps\n",
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import json\n",
    "import geocoder\n",
    "import mlrose\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "KEY_file = open('key.txt', 'r')\n",
    "KEY=KEY_file.readlines()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class Gsearch_python:\n",
    "    \n",
    "    def __init__(self, name_search):\n",
    "        \n",
    "        self.name = name_search\n",
    "        \n",
    "    def Gsearch(self):\n",
    "        \n",
    "        count = 0\n",
    "        results = []\n",
    "        \n",
    "        try:\n",
    "            from googlesearch import search\n",
    "        except ImportError:\n",
    "             print(\"No Module named 'google' Found\")\n",
    "        for i in search(query=self.name,tld='co.in',lang='en',num=10,stop=10,pause=2):\n",
    "            results.append(i)\n",
    "        return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def places(city):\n",
    "    \n",
    "    gs = Gsearch_python(\"Tripadvisor %s\" % (city))\n",
    "    res = gs.Gsearch()\n",
    "\n",
    "    for i in range(len(res)):\n",
    "        if re.search(\"https://www.tripadvisor.com/Tourism\", res[i]) != None:\n",
    "            trip = i\n",
    "            break\n",
    "\n",
    "    URL = res[i]\n",
    "    r = requests.get(URL) \n",
    "\n",
    "    soup = BeautifulSoup(r.content, 'html5lib') \n",
    "    \n",
    "    places = []\n",
    "\n",
    "    for place in soup.find_all('span', attrs={'class', 'social-shelf-items-ShelfLocationSection__name--CdA_A'}):\n",
    "        places.append(place.text)\n",
    "        \n",
    "    return places\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "good_types = ['amusement_park', 'aquarium', 'art_gallery', 'bakery',\n",
    "    'book_store', 'bowling_alley', 'campground',\n",
    "    'casino', 'cemetery', 'church', 'city_hall', 'courthouse',\n",
    "    'embassy', 'hindu_temple', 'jewelry_store', 'library',\n",
    "    'mosque', 'museum', 'park', 'stadium', 'synagogue', 'tourist_attraction', 'zoo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def info(place):\n",
    "\n",
    "    gmaps = googlemaps.Client(key=KEY)\n",
    "\n",
    "    geocode_result = gmaps.geocode(place)\n",
    "    place_id = geocode_result[0]['place_id']\n",
    "\n",
    "    URL2 = 'https://maps.googleapis.com/maps/api/place/details/json?place_id=%s&fields=name,rating,photos,type&key=%s'% (place_id, KEY)\n",
    "    r2 = requests.get(URL2)\n",
    "    soup2 = BeautifulSoup(r2.content, 'html5lib') \n",
    "    res2 = json.loads(r2.text)\n",
    "    \n",
    "    if not set(res2['result']['types']).isdisjoint(good_types):\n",
    "\n",
    "        lat = geocode_result[0]['geometry']['location']['lat']\n",
    "        long = geocode_result[0]['geometry']['location']['lng']\n",
    "        kind = res2['result']['types'][0]\n",
    "        try:\n",
    "            rating = float('%.4g' % str(res2['result']['rating']))\n",
    "        except:\n",
    "            rating = 4.5\n",
    "\n",
    "        return lat, long, rating, kind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def place_data(place, offline = False):\n",
    "    \n",
    "    if offline == True:\n",
    "    \n",
    "        mem = np.load('memory.npz')\n",
    "        try:\n",
    "            return mem[place].item()\n",
    "        except:\n",
    "            data = None\n",
    "    \n",
    "    else:\n",
    "    \n",
    "        loc = places(place)\n",
    "\n",
    "        data = {}\n",
    "\n",
    "        for i in range(len(loc)):\n",
    "\n",
    "            place_info = info(place + loc[i])\n",
    "\n",
    "            if (place_info != None) and (place_info not in data.values()):\n",
    "\n",
    "                data[loc[i]] = place_info\n",
    "\n",
    "        mem = {place: data}\n",
    "        np.savez('memory.npz', **mem)\n",
    "\n",
    "        return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data = place_data('New Haven', offline=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "names = list(data.keys())\n",
    "ratings = list(np.array(list(data.values()))[:, 2])\n",
    "lats = np.array(list(data.values()), dtype=str)[:, 0]\n",
    "longs = np.array(list(data.values()), dtype=str)[:, 1]\n",
    "comma = np.full(lats.shape, ',')\n",
    "locations = list(np.core.defchararray.add(np.core.defchararray.add(lats, comma), longs))\n",
    "kinds = list(np.array(list(data.values()))[:, 3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sp(place):\n",
    "    \n",
    "    if place == 'current':\n",
    "        g = geocoder.ip('me')\n",
    "        sp = str(g.latlng[0]) + ',' + str(g.latlng[1])\n",
    "    else:\n",
    "        \n",
    "        gmaps = googlemaps.Client(key=KEY)\n",
    "        \n",
    "        geocode_result = gmaps.geocode(place)\n",
    "        lat = geocode_result[0]['geometry']['location']['lat']\n",
    "        long = geocode_result[0]['geometry']['location']['lng']\n",
    "        sp = str(lat) + ',' + str(long)\n",
    "        \n",
    "    return sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "res2 = json.loads(r2.text)\n",
    "photo_ref = res2['result']['photos'][0]['photo_reference']\n",
    "\n",
    "URL3 = 'https://maps.googleapis.com/maps/api/place/photo?maxwidth=400&photoreference=%s&key=AIzaSyCp1XU9QMczMh_iDm8hEKrWjYu4ZY2ki5k' % photo_ref\n",
    "\n",
    "r3 = requests.get(URL3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 520,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def pic(place):\n",
    "\n",
    "    response = google_images_download.googleimagesdownload()   #class instantiation\n",
    "\n",
    "    arguments = {\"keywords\":\"%s %s\" % (city, place),\"limit\":1,\"print_urls\":True}\n",
    "    paths = response.download(arguments)\n",
    "    img = Image(filename=paths[0][city + ' ' + place][0])\n",
    "    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6, 4, 0, 5, 1, 7, 3]\n",
      "11.905880899790658\n"
     ]
    }
   ],
   "source": [
    "gmaps = googlemaps.Client(key=KEY)\n",
    "\n",
    "now=datetime.now()\n",
    "\n",
    "def google(n, locations):\n",
    "    gmaps_matrix = gmaps.distance_matrix(locations, locations,\n",
    "                        mode=\"driving\",\n",
    "                        avoid=\"ferries\",\n",
    "                        departure_time=now)\n",
    "\n",
    "    matrix = np.ndarray(dtype=\"double\", shape=(n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            matrix[i][j] = gmaps_matrix['rows'][i]['elements'][j]['duration_in_traffic']['value']\n",
    "\n",
    "    return matrix\n",
    "\n",
    "def getMat(iArr, matrix):\n",
    "    n = len(iArr)\n",
    "    new_mat = np.ndarray(dtype=\"double\", shape=(n,n))\n",
    "    for i in range(n):\n",
    "        for j in range(n):\n",
    "            new_mat[i][j] = matrix[iArr[i]][iArr[j]]\n",
    "\n",
    "    return new_mat\n",
    "\n",
    "def binary(n, digits):\n",
    "    binary = str(\"{0:b}\".format(n))\n",
    "    return (digits-len(binary))*\"0\"+binary\n",
    "\n",
    "def find_route(n, matrix, time_limit):\n",
    "    good = []\n",
    "    for i in range(1, 2**(n-1)):\n",
    "        bin = binary(i, n-1)+\"1\"\n",
    "        iArr = []\n",
    "        posArr = []\n",
    "        for j in range(n - 1):\n",
    "            if(bin[j]=='1'):\n",
    "                iArr.append(j)\n",
    "                posArr.append(locations[j])\n",
    "\n",
    "        if(len(iArr)>1):\n",
    "            new_mat = getMat(iArr, matrix)\n",
    "            dist_list = []\n",
    "            for j in range(len(iArr)):\n",
    "                for k in range(j+1, len(iArr)):\n",
    "                    dist_list.append((j, k, new_mat[j][k]))\n",
    "\n",
    "            fitness_dists = mlrose.TravellingSales(distances=dist_list)\n",
    "            problem_fit = mlrose.TSPOpt(length=len(iArr), fitness_fn=fitness_dists, maximize=False)\n",
    "            best_state, best_fitness = mlrose.genetic_alg(problem_fit, random_state=2)\n",
    "\n",
    "            best_state_fr = []\n",
    "            for k in range(len(iArr)):\n",
    "                best_state_fr.append(iArr[best_state[k]])\n",
    "\n",
    "            if(best_fitness<time_limit):\n",
    "                good.append(best_state_fr)\n",
    "\n",
    "    return good\n",
    "\n",
    "def value(path, ratings):\n",
    "    n = len(path)\n",
    "    sum = 0\n",
    "    for i in range(n):\n",
    "        if(path[i]!=len(ratings)):\n",
    "            sum+=float(ratings[path[i]])\n",
    "    return sum/n**(0.5)\n",
    "\n",
    "def best(good, ratings):\n",
    "    values = []\n",
    "    for i in range(len(good)):\n",
    "        values.append(value(good[i], ratings))\n",
    "\n",
    "    max = 0\n",
    "    loc = -1\n",
    "\n",
    "    for i in range(len(good)):\n",
    "        if(values[i]>max):\n",
    "            max = values[i]\n",
    "            loc = i\n",
    "\n",
    "    return good[i]\n",
    "\n",
    "n = len(locations)\n",
    "\n",
    "time_limit = 3600\n",
    "\n",
    "sp = get_sp('current')\n",
    "\n",
    "def get_path(n, locations, ratings, names, kinds, sp, time_limit):\n",
    "    locations = np.append(locations, sp)\n",
    "    n+=1\n",
    "\n",
    "    matrix = google(n, locations)\n",
    "    good = find_route(n, matrix, time_limit)\n",
    "    best_route = best(good, ratings)\n",
    "\n",
    "    return best_route\n",
    "\n",
    "route = get_path(n, locations, ratings, names, kinds, sp, time_limit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grove Street Cemetery\n",
      "Yale University Art Gallery\n",
      "New Haven Green\n",
      "Knights of Columbus Museum\n",
      "East Rock Park\n",
      "Yale Peabody Museum of Natural History\n",
      "Beinecke Rare Book & Manuscript Library\n"
     ]
    }
   ],
   "source": [
    "for i in [6, 4, 0, 5, 1, 7, 3]:\n",
    "    print(names[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "data_small = {}\n",
    "\n",
    "for i in range(9):\n",
    "    data_small[list(data.keys())[i]] = list(data.values())[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "names = list(data_small.keys())\n",
    "ratings = np.array(list(data_small.values()))[:, 2]\n",
    "lats = np.array(list(data_small.values()), dtype=str)[:, 0]\n",
    "longs = np.array(list(data_small.values()), dtype=str)[:, 1]\n",
    "comma = np.full(lats.shape, ',')\n",
    "locations = np.core.defchararray.add(np.core.defchararray.add(lats, comma), longs)\n",
    "kinds = np.array(list(data_small.values()))[:, 3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Atticus Bookstore & Cafe': (41.3078779, -72.93063049999999, 4.5, 'cafe'),\n",
       " 'Book Trader Cafe': (41.30840140000001, -72.9320257, 4.5, 'book_store'),\n",
       " 'Carousel at Lighthouse Point Park': (41.2488564,\n",
       "  -72.9035323,\n",
       "  4.5,\n",
       "  'tourist_attraction'),\n",
       " 'Grove Street Cemetery': (41.31377500000001, -72.927052, 4.5, 'cemetery'),\n",
       " 'Knights of Columbus Museum': (41.3023979,\n",
       "  -72.9243855,\n",
       "  4.5,\n",
       "  'tourist_attraction'),\n",
       " 'New Haven Green': (41.3081574, -72.9261243, 4.5, 'park'),\n",
       " 'New Haven Museum': (41.3140015, -72.9220398, 4.5, 'tourist_attraction'),\n",
       " 'Yale Center for British Art': (41.3078876,\n",
       "  -72.930876,\n",
       "  4.5,\n",
       "  'tourist_attraction'),\n",
       " 'Yale Peabody Museum of Natural History': (41.3159747,\n",
       "  -72.9212252,\n",
       "  4.5,\n",
       "  'tourist_attraction'),\n",
       " 'Yale University Art Gallery': (41.30839,\n",
       "  -72.93095799999999,\n",
       "  4.5,\n",
       "  'tourist_attraction')}"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:anaconda]",
   "language": "python",
   "name": "conda-env-anaconda-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
